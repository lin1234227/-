{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入需要用到的模型的库包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T03:59:54.236900Z",
     "start_time": "2019-06-28T03:59:53.247639Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "# CatBoost\n",
    "import catboost as cb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.corpora import WikiCorpus\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler() \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC,LinearRegression,LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T08:01:43.899948Z",
     "start_time": "2019-06-03T08:01:43.794924Z"
    }
   },
   "source": [
    "## 读取特征\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pinkman "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:45.617022Z",
     "start_time": "2019-06-04T15:41:44.717820Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取pinkman特征\n",
      "(40006, 243) (2401, 243)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_path = 'D:/城市-房产租金预测/stacking/pinkman.pkl'\n",
    "data_fp = open(features_path, 'rb')\n",
    "train, test = pickle.load(data_fp)\n",
    "print(\"读取pinkman特征\")\n",
    "data_fp.close()\n",
    "target = train.pop(\"tradeMoney\")\n",
    "test.drop([\"ID\"],axis = 1, inplace=True)\n",
    "train.drop([\"ID\"],axis = 1, inplace=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4)\n",
    "pinkman_train, pinkman_test, pinkman_target = train,test,target\n",
    "pinkman_train = pinkman_train.astype(float)\n",
    "pinkman_test = pinkman_test.astype(float)\n",
    "print(pinkman_train.shape,pinkman_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:46.461212Z",
     "start_time": "2019-06-04T15:41:46.414202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bath</th>\n",
       "      <th>Hall</th>\n",
       "      <th>Room</th>\n",
       "      <th>area</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>plate</th>\n",
       "      <th>pv</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster10</th>\n",
       "      <th>communityName_houseToward_nunique</th>\n",
       "      <th>communityName_houseType_nunique</th>\n",
       "      <th>plate_houseToward_nunique</th>\n",
       "      <th>plate_houseType_nunique</th>\n",
       "      <th>communityName_totalFloor_mean</th>\n",
       "      <th>plate_totalFloor_mean</th>\n",
       "      <th>communityName_houseDecoration_mean</th>\n",
       "      <th>plate_houseDecoration_mean</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40006</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>76.20</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.846154</td>\n",
       "      <td>9.866115</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>0.932367</td>\n",
       "      <td>5090.613296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.137778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>3868.608230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93.00</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>33164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.500305</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>6574.183442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40009</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>42179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>10.500305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>4429.405550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40010</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>103.75</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17471.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.500305</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>9042.396010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bath  Hall  Room    area  buildYear  houseDecoration  houseFloor  \\\n",
       "40006   1.0   1.0   2.0   76.20     2006.0              0.0         0.0   \n",
       "40007   1.0   1.0   1.0   35.00     1995.0              0.0         2.0   \n",
       "40008   1.0   2.0   2.0   93.00     2003.0              0.0         1.0   \n",
       "40009   1.0   1.0   2.0   70.00     1997.0              0.0         1.0   \n",
       "40010   1.0   2.0   3.0  103.75     2013.0              0.0         1.0   \n",
       "\n",
       "       houseToward  plate       pv  ...  cluster10  \\\n",
       "40006          5.0   50.0  15244.0  ...        2.0   \n",
       "40007          4.0   28.0    687.0  ...        3.0   \n",
       "40008          5.0   53.0  33164.0  ...        2.0   \n",
       "40009          5.0   53.0  42179.0  ...        2.0   \n",
       "40010          6.0   53.0  17471.0  ...        2.0   \n",
       "\n",
       "       communityName_houseToward_nunique  communityName_houseType_nunique  \\\n",
       "40006                                3.0                              3.0   \n",
       "40007                                2.0                              2.0   \n",
       "40008                                2.0                              3.0   \n",
       "40009                                2.0                              2.0   \n",
       "40010                                6.0                              6.0   \n",
       "\n",
       "       plate_houseToward_nunique  plate_houseType_nunique  \\\n",
       "40006                        7.0                     23.0   \n",
       "40007                        8.0                     14.0   \n",
       "40008                        9.0                     22.0   \n",
       "40009                        9.0                     22.0   \n",
       "40010                        9.0                     22.0   \n",
       "\n",
       "       communityName_totalFloor_mean  plate_totalFloor_mean  \\\n",
       "40006                       8.846154               9.866115   \n",
       "40007                       6.000000              13.137778   \n",
       "40008                      11.000000              10.500305   \n",
       "40009                       6.500000              10.500305   \n",
       "40010                      18.000000              10.500305   \n",
       "\n",
       "       communityName_houseDecoration_mean  plate_houseDecoration_mean  \\\n",
       "40006                            1.076923                    0.932367   \n",
       "40007                            0.000000                    0.546667   \n",
       "40008                            0.600000                    0.685400   \n",
       "40009                            0.000000                    0.685400   \n",
       "40010                            0.984127                    0.685400   \n",
       "\n",
       "               pre  \n",
       "40006  5090.613296  \n",
       "40007  3868.608230  \n",
       "40008  6574.183442  \n",
       "40009  4429.405550  \n",
       "40010  9042.396010  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinkman_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jason特征V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:48.945774Z",
     "start_time": "2019-06-04T15:41:48.381646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39618, 43) (2401, 43)\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/城市-房产租金预测/stacking/'\n",
    "train_df = open(path+\"Jason_stacking_train_v1.csv\",\"rb\")\n",
    "test_df = open(path+\"Jason_stacking_test_v1.csv\",\"rb\")\n",
    "Jason_train_v1 = pd.read_csv(train_df)\n",
    "Jason_test_v1 = pd.read_csv(test_df)\n",
    "Jason_target_v1 = Jason_train_v1.pop(\"tradeMoney\")\n",
    "categorical_feats = ['houseDecoration', 'plate', 'rentType']\n",
    "def cat2num(data):\n",
    "    for i in categorical_feats:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(0, data[i].nunique()))))\n",
    "    return data\n",
    "Jason_train_v1 = cat2num(Jason_train_v1)\n",
    "Jason_test_v1 = cat2num(Jason_test_v1)\n",
    "Jason_train_v1.drop([\"ID\"],axis = 1, inplace=True)\n",
    "Jason_test_v1.drop([\"ID\"],axis = 1, inplace=True)\n",
    "print(Jason_train_v1.shape,Jason_test_v1.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jason特征V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:50.279074Z",
     "start_time": "2019-06-04T15:41:49.716946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39618, 42) (2401, 42)\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/城市-房产租金预测/stacking/'\n",
    "train_df = open(path+\"Jason_stacking_train_v2.csv\",\"rb\")\n",
    "test_df = open(path+\"Jason_stacking_test_v2.csv\",\"rb\")\n",
    "Jason_train_v2 = pd.read_csv(train_df)\n",
    "Jason_test_v2 = pd.read_csv(test_df)\n",
    "Jason_target_v2 = Jason_train_v2.pop(\"tradeMoney\")\n",
    "categorical_feats = ['houseDecoration', 'plate', 'rentType']\n",
    "def cat2num(data):\n",
    "    for i in categorical_feats:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(0, data[i].nunique()))))\n",
    "    return data\n",
    "Jason_train_v2 = cat2num(Jason_train_v2)\n",
    "Jason_test_v2 = cat2num(Jason_test_v2)\n",
    "Jason_train_v2.drop([\"ID\"],axis = 1, inplace=True)\n",
    "Jason_test_v2.drop([\"ID\"],axis = 1, inplace=True)\n",
    "print(Jason_train_v2.shape,Jason_test_v2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:50.955226Z",
     "start_time": "2019-06-04T15:41:50.933221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>plate</th>\n",
       "      <th>buildYear</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>hall</th>\n",
       "      <th>wc</th>\n",
       "      <th>tradeMonth</th>\n",
       "      <th>communityNameW0</th>\n",
       "      <th>...</th>\n",
       "      <th>Groupby_communityName_pv_std</th>\n",
       "      <th>Groupby_communityName_bedroom_std</th>\n",
       "      <th>Groupby_communityName_totalTradeMoney_median</th>\n",
       "      <th>Groupby_communityName_totalFloor_mean</th>\n",
       "      <th>Count_communityName</th>\n",
       "      <th>Count_totalFloor</th>\n",
       "      <th>Count_communityName_newWorkers</th>\n",
       "      <th>Count_communityName_bedroom</th>\n",
       "      <th>rentType</th>\n",
       "      <th>train_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.06</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.038550</td>\n",
       "      <td>...</td>\n",
       "      <td>3505.978988</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>5.077100e+08</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>1197</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5971.670451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.55</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.047079</td>\n",
       "      <td>...</td>\n",
       "      <td>2142.516604</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>13.181818</td>\n",
       "      <td>11</td>\n",
       "      <td>2275</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2419.196923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132.00</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.035118</td>\n",
       "      <td>...</td>\n",
       "      <td>5048.220426</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>1.687285e+09</td>\n",
       "      <td>29.451613</td>\n",
       "      <td>31</td>\n",
       "      <td>239</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12846.002864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.00</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.023838</td>\n",
       "      <td>...</td>\n",
       "      <td>13826.332598</td>\n",
       "      <td>0.389118</td>\n",
       "      <td>4.758300e+08</td>\n",
       "      <td>17.833333</td>\n",
       "      <td>60</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2035.895644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>...</td>\n",
       "      <td>7521.251340</td>\n",
       "      <td>0.619139</td>\n",
       "      <td>1.093100e+08</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>16</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3189.746127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  totalFloor  houseDecoration  plate  buildYear  bedroom  hall  wc  \\\n",
       "0   68.06          16                0      0       1953        2     1   1   \n",
       "1  125.55          14                1      1       2007        3     2   2   \n",
       "2  132.00          32                0      2       1994        3     2   2   \n",
       "3   57.00          17                2      3       1994        1     1   1   \n",
       "4  129.00           2                3      4       1994        3     2   3   \n",
       "\n",
       "   tradeMonth  communityNameW0  ...  Groupby_communityName_pv_std  \\\n",
       "0          11         0.038550  ...                   3505.978988   \n",
       "1          12        -0.047079  ...                   2142.516604   \n",
       "2          12        -0.035118  ...                   5048.220426   \n",
       "3          12        -0.023838  ...                  13826.332598   \n",
       "4          11         0.023886  ...                   7521.251340   \n",
       "\n",
       "   Groupby_communityName_bedroom_std  \\\n",
       "0                           0.516398   \n",
       "1                           0.522233   \n",
       "2                           0.762001   \n",
       "3                           0.389118   \n",
       "4                           0.619139   \n",
       "\n",
       "   Groupby_communityName_totalTradeMoney_median  \\\n",
       "0                                  5.077100e+08   \n",
       "1                                  5.000000e+06   \n",
       "2                                  1.687285e+09   \n",
       "3                                  4.758300e+08   \n",
       "4                                  1.093100e+08   \n",
       "\n",
       "   Groupby_communityName_totalFloor_mean  Count_communityName  \\\n",
       "0                              10.166667                    6   \n",
       "1                              13.181818                   11   \n",
       "2                              29.451613                   31   \n",
       "3                              17.833333                   60   \n",
       "4                               4.750000                   16   \n",
       "\n",
       "   Count_totalFloor  Count_communityName_newWorkers  \\\n",
       "0              1197                               1   \n",
       "1              2275                               1   \n",
       "2               239                               4   \n",
       "3              1441                               3   \n",
       "4               194                               2   \n",
       "\n",
       "   Count_communityName_bedroom  rentType     train_pre  \n",
       "0                            2         0   5971.670451  \n",
       "1                            6         0   2419.196923  \n",
       "2                           12         0  12846.002864  \n",
       "3                           53         0   2035.895644  \n",
       "4                            8         0   3189.746127  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jason_train_v2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T13:59:19.447303Z",
     "start_time": "2019-06-03T13:59:19.424298Z"
    }
   },
   "source": [
    "### hero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:53.747856Z",
     "start_time": "2019-06-04T15:41:52.323535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39504, 151) (2401, 151)\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/城市-房产租金预测/stacking/'\n",
    "train_df = open(path+\"hero_stacking_train.csv\",\"rb\")\n",
    "test_df = open(path+\"hero_stacking_test.csv\",\"rb\")\n",
    "hero_train = pd.read_csv(train_df)\n",
    "hero_test = pd.read_csv(test_df)\n",
    "# hero_train.drop([\"ID\"],axis = 1, inplace=True)\n",
    "# hero_test.drop([\"ID\"],axis = 1, inplace=True)\n",
    "# hero_train[\"ID\"] = hero_train[\"ID\"].astype(int)\n",
    "# hero_test[\"ID\"] = hero_test[\"ID\"].astype(int)\n",
    "hero_train.drop([\"Unnamed: 0\",\"ID\",\"city\"],axis = 1, inplace=True)\n",
    "hero_test.drop([\"Unnamed: 0\",\"ID\",\"city\"],axis = 1, inplace=True)\n",
    "print(hero_train.shape,hero_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:54.396003Z",
     "start_time": "2019-06-04T15:41:54.372997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rentType</th>\n",
       "      <th>houseType</th>\n",
       "      <th>houseFloor</th>\n",
       "      <th>totalFloor</th>\n",
       "      <th>houseToward</th>\n",
       "      <th>houseDecoration</th>\n",
       "      <th>communityName</th>\n",
       "      <th>region</th>\n",
       "      <th>plate</th>\n",
       "      <th>...</th>\n",
       "      <th>plateW0</th>\n",
       "      <th>plateW1</th>\n",
       "      <th>plateW2</th>\n",
       "      <th>plateW3</th>\n",
       "      <th>plateW4</th>\n",
       "      <th>plateW5</th>\n",
       "      <th>plateW6</th>\n",
       "      <th>plateW7</th>\n",
       "      <th>cluster1</th>\n",
       "      <th>train_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550193</td>\n",
       "      <td>-2.172251</td>\n",
       "      <td>-1.498352</td>\n",
       "      <td>0.640507</td>\n",
       "      <td>1.451142</td>\n",
       "      <td>0.468397</td>\n",
       "      <td>1.712500</td>\n",
       "      <td>-2.903254</td>\n",
       "      <td>7</td>\n",
       "      <td>5865.904441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220966</td>\n",
       "      <td>-3.330363</td>\n",
       "      <td>0.561736</td>\n",
       "      <td>1.946966</td>\n",
       "      <td>2.904222</td>\n",
       "      <td>0.168849</td>\n",
       "      <td>0.381790</td>\n",
       "      <td>-2.022188</td>\n",
       "      <td>2</td>\n",
       "      <td>1790.163705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186082</td>\n",
       "      <td>-2.562744</td>\n",
       "      <td>-0.801996</td>\n",
       "      <td>-1.299095</td>\n",
       "      <td>3.000661</td>\n",
       "      <td>0.656332</td>\n",
       "      <td>-0.292044</td>\n",
       "      <td>0.742765</td>\n",
       "      <td>2</td>\n",
       "      <td>1946.767365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1257</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348185</td>\n",
       "      <td>-0.729719</td>\n",
       "      <td>0.447798</td>\n",
       "      <td>0.350268</td>\n",
       "      <td>2.359439</td>\n",
       "      <td>0.482003</td>\n",
       "      <td>0.714489</td>\n",
       "      <td>-1.120475</td>\n",
       "      <td>9</td>\n",
       "      <td>3568.743583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  rentType  houseType  houseFloor  totalFloor  houseToward  \\\n",
       "0   68.06         0          0           0          16            0   \n",
       "1  125.55         1          1           1          14            0   \n",
       "2   57.00         1          2           1          17            0   \n",
       "3  129.00         1          3           0           2            0   \n",
       "\n",
       "   houseDecoration  communityName  region  plate  ...   plateW0   plateW1  \\\n",
       "0                0             51       1     64  ...  0.550193 -2.172251   \n",
       "1                1            130       2     49  ...  0.220966 -3.330363   \n",
       "2                2            313       2     51  ... -0.186082 -2.562744   \n",
       "3                3           1257       3     44  ...  0.348185 -0.729719   \n",
       "\n",
       "    plateW2   plateW3   plateW4   plateW5   plateW6   plateW7  cluster1  \\\n",
       "0 -1.498352  0.640507  1.451142  0.468397  1.712500 -2.903254         7   \n",
       "1  0.561736  1.946966  2.904222  0.168849  0.381790 -2.022188         2   \n",
       "2 -0.801996 -1.299095  3.000661  0.656332 -0.292044  0.742765         2   \n",
       "3  0.447798  0.350268  2.359439  0.482003  0.714489 -1.120475         9   \n",
       "\n",
       "     train_pre  \n",
       "0  5865.904441  \n",
       "1  1790.163705  \n",
       "2  1946.767365  \n",
       "3  3568.743583  \n",
       "\n",
       "[4 rows x 151 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero_train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:03:59.152107Z",
     "start_time": "2019-06-03T14:03:59.128101Z"
    }
   },
   "source": [
    "### heitao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:56.340911Z",
     "start_time": "2019-06-04T15:41:55.662288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取特征\n",
      "(40126, 232) (2401, 232)\n"
     ]
    }
   ],
   "source": [
    "features_path = 'D:/城市-房产租金预测/stacking/heitao.pkl'\n",
    "data_fp = open(features_path, 'rb')\n",
    "heitao_train, heitao_test = pickle.load(data_fp)\n",
    "heitao_target = heitao_train.pop(\"target\")\n",
    "heitao_train.drop([\"ID\"],axis = 1, inplace=True)\n",
    "heitao_test.drop([\"ID\"],axis = 1, inplace=True)\n",
    "print(\"读取特征\")\n",
    "data_fp.close()\n",
    "print(heitao_train.shape,heitao_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:41:57.717222Z",
     "start_time": "2019-06-04T15:41:57.693216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bath</th>\n",
       "      <th>Hall</th>\n",
       "      <th>Room</th>\n",
       "      <th>Room_Bath</th>\n",
       "      <th>Schoo_ratio</th>\n",
       "      <th>all_SchoolNum</th>\n",
       "      <th>all_SchoolNum_buildYear_cluster_mean</th>\n",
       "      <th>all_SchoolNum_communityName_cluster_mean</th>\n",
       "      <th>all_SchoolNum_houseDecoration_cluster_mean</th>\n",
       "      <th>all_SchoolNum_plate_cluster_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>trainsportNum_all_hospitalNum_cluster5_mean</th>\n",
       "      <th>trainsportNum_all_mall_cluster5_mean</th>\n",
       "      <th>trainsportNum_otherNum_cluster5_mean</th>\n",
       "      <th>all_SchoolNum_all_hospitalNum_cluster5_mean</th>\n",
       "      <th>all_SchoolNum_all_mall_cluster5_mean</th>\n",
       "      <th>all_SchoolNum_otherNum_cluster5_mean</th>\n",
       "      <th>all_hospitalNum_all_mall_cluster5_mean</th>\n",
       "      <th>all_hospitalNum_otherNum_cluster5_mean</th>\n",
       "      <th>all_mall_otherNum_cluster5_mean</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.737603</td>\n",
       "      <td>2.637199</td>\n",
       "      <td>0.734387</td>\n",
       "      <td>3.928964</td>\n",
       "      <td>0.736073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668591</td>\n",
       "      <td>0.743583</td>\n",
       "      <td>2.248453</td>\n",
       "      <td>0.668591</td>\n",
       "      <td>0.743583</td>\n",
       "      <td>2.248453</td>\n",
       "      <td>0.743583</td>\n",
       "      <td>2.248453</td>\n",
       "      <td>2.248453</td>\n",
       "      <td>3548.599153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.537363</td>\n",
       "      <td>3.287083</td>\n",
       "      <td>0.536032</td>\n",
       "      <td>4.087380</td>\n",
       "      <td>0.536811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926685</td>\n",
       "      <td>1.250710</td>\n",
       "      <td>2.533498</td>\n",
       "      <td>0.926685</td>\n",
       "      <td>1.250710</td>\n",
       "      <td>2.533498</td>\n",
       "      <td>1.250710</td>\n",
       "      <td>2.533498</td>\n",
       "      <td>2.533498</td>\n",
       "      <td>1904.003447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>2.555343</td>\n",
       "      <td>3.998208</td>\n",
       "      <td>2.564502</td>\n",
       "      <td>3.928964</td>\n",
       "      <td>2.561292</td>\n",
       "      <td>...</td>\n",
       "      <td>1.799298</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>3.515890</td>\n",
       "      <td>1.799298</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>3.515890</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>3.515890</td>\n",
       "      <td>3.515890</td>\n",
       "      <td>15601.905397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>4.096610</td>\n",
       "      <td>3.998208</td>\n",
       "      <td>4.099168</td>\n",
       "      <td>3.048312</td>\n",
       "      <td>4.101421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.125046</td>\n",
       "      <td>1.727672</td>\n",
       "      <td>3.852481</td>\n",
       "      <td>5.125046</td>\n",
       "      <td>1.727672</td>\n",
       "      <td>3.852481</td>\n",
       "      <td>1.727672</td>\n",
       "      <td>3.852481</td>\n",
       "      <td>3.852481</td>\n",
       "      <td>1857.312781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bath  Hall  Room  Room_Bath  Schoo_ratio  all_SchoolNum  \\\n",
       "0     1     1     2   0.666667        0.010       0.737603   \n",
       "1     2     2     3   0.750000        0.050       0.537363   \n",
       "2     2     2     3   0.750000        0.026       2.555343   \n",
       "3     1     1     1   1.000000        0.047       4.096610   \n",
       "\n",
       "   all_SchoolNum_buildYear_cluster_mean  \\\n",
       "0                              2.637199   \n",
       "1                              3.287083   \n",
       "2                              3.998208   \n",
       "3                              3.998208   \n",
       "\n",
       "   all_SchoolNum_communityName_cluster_mean  \\\n",
       "0                                  0.734387   \n",
       "1                                  0.536032   \n",
       "2                                  2.564502   \n",
       "3                                  4.099168   \n",
       "\n",
       "   all_SchoolNum_houseDecoration_cluster_mean  \\\n",
       "0                                    3.928964   \n",
       "1                                    4.087380   \n",
       "2                                    3.928964   \n",
       "3                                    3.048312   \n",
       "\n",
       "   all_SchoolNum_plate_cluster_mean  ...  \\\n",
       "0                          0.736073  ...   \n",
       "1                          0.536811  ...   \n",
       "2                          2.561292  ...   \n",
       "3                          4.101421  ...   \n",
       "\n",
       "   trainsportNum_all_hospitalNum_cluster5_mean  \\\n",
       "0                                     0.668591   \n",
       "1                                     0.926685   \n",
       "2                                     1.799298   \n",
       "3                                     5.125046   \n",
       "\n",
       "   trainsportNum_all_mall_cluster5_mean  trainsportNum_otherNum_cluster5_mean  \\\n",
       "0                              0.743583                              2.248453   \n",
       "1                              1.250710                              2.533498   \n",
       "2                              0.999422                              3.515890   \n",
       "3                              1.727672                              3.852481   \n",
       "\n",
       "   all_SchoolNum_all_hospitalNum_cluster5_mean  \\\n",
       "0                                     0.668591   \n",
       "1                                     0.926685   \n",
       "2                                     1.799298   \n",
       "3                                     5.125046   \n",
       "\n",
       "   all_SchoolNum_all_mall_cluster5_mean  all_SchoolNum_otherNum_cluster5_mean  \\\n",
       "0                              0.743583                              2.248453   \n",
       "1                              1.250710                              2.533498   \n",
       "2                              0.999422                              3.515890   \n",
       "3                              1.727672                              3.852481   \n",
       "\n",
       "   all_hospitalNum_all_mall_cluster5_mean  \\\n",
       "0                                0.743583   \n",
       "1                                1.250710   \n",
       "2                                0.999422   \n",
       "3                                1.727672   \n",
       "\n",
       "   all_hospitalNum_otherNum_cluster5_mean  all_mall_otherNum_cluster5_mean  \\\n",
       "0                                2.248453                         2.248453   \n",
       "1                                2.533498                         2.533498   \n",
       "2                                3.515890                         3.515890   \n",
       "3                                3.852481                         3.852481   \n",
       "\n",
       "            pre  \n",
       "0   3548.599153  \n",
       "1   1904.003447  \n",
       "2  15601.905397  \n",
       "3   1857.312781  \n",
       "\n",
       "[4 rows x 232 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heitao_train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:42:00.047747Z",
     "start_time": "2019-06-04T15:41:59.364593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取特征\n",
      "(40006, 242) (2401, 242) (40006,)\n"
     ]
    }
   ],
   "source": [
    "features_path = 'D:/城市-房产租金预测/stacking/yb.pkl'\n",
    "data_fp = open(features_path, 'rb')\n",
    "yb_train, yb_test = pickle.load(data_fp)\n",
    "yb_target = yb_train.pop(\"tradeMoney\")\n",
    "yb_train.drop([\"ID\"],axis = 1, inplace=True)\n",
    "yb_test.drop([\"ID\"],axis = 1, inplace=True)\n",
    "print(\"读取特征\")\n",
    "data_fp.close()\n",
    "print(yb_train.shape,yb_test.shape,yb_target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### airen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:42:04.117666Z",
     "start_time": "2019-06-04T15:42:02.693344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取特征\n",
      "(37663, 521) (4870, 521) (37663,)\n"
     ]
    }
   ],
   "source": [
    "features_path = 'D:/城市-房产租金预测/stacking/airen.pkl'\n",
    "data_fp = open(features_path, 'rb')\n",
    "airen_train, airen_test = pickle.load(data_fp)\n",
    "airen_target = airen_train.pop(\"tradeMoney\")\n",
    "airen_train.drop([\"ID\",\"areaMoney\"],axis = 1, inplace=True)\n",
    "airen_test.drop([\"ID\"],axis = 1, inplace=True)\n",
    "print(\"读取特征\")\n",
    "data_fp.close()\n",
    "print(airen_train.shape,airen_test.shape,airen_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果简要分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T04:51:50.693568Z",
     "start_time": "2019-06-06T04:51:50.688577Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def online_score(pred):\n",
    "    print(\"预测结果最大值：{},预测结果最小值：{}\".format(pred.max(),pred.min()))\n",
    "    # a榜测分\n",
    "    conmbine1 = pd.read_csv(\"D:/城市-房产租金预测/best_result/sub_a_913.csv\",engine = \"python\",header=None)\n",
    "    score1 = r2_score(pred, conmbine1)\n",
    "    # b榜测分\n",
    "    conmbine3 = pd.read_csv(\"D:/城市-房产租金预测/best_result/sub_b_9194.csv\",engine = \"python\",header=None)\n",
    "    score3= r2_score(pred, conmbine3)\n",
    "\n",
    "    print(\"对比919分数:{}\".format(score3))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:42:19.116048Z",
     "start_time": "2019-06-04T15:42:19.095044Z"
    }
   },
   "outputs": [],
   "source": [
    "#LASSO Regression :  该模型可能对异常值非常敏感。 所以我们需要让它们更加健壮。 为此，我们在管道上使用sklearn的Robustscaler（）方法\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    " \n",
    "#Elastic Net Regression 同上\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    " \n",
    "#Gradient Boosting Regression :huber损失有很好的鲁棒性\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    " \n",
    "#xgb\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=5000,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                              nthread = -1)\n",
    "\n",
    "\n",
    "#lgb\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',\n",
    "                              num_leaves=31,\n",
    "                              boosting = \"gbdt\",\n",
    "                              learning_rate=0.01, \n",
    "                              n_estimators=720,\n",
    "                              max_bin = 55, \n",
    "                              bagging_fraction = 0.8,\n",
    "                              bagging_freq = 1, \n",
    "                              feature_fraction = 0.85,\n",
    "                              feature_fraction_seed=9, \n",
    "                              bagging_seed=23,\n",
    "                              min_child_samples = 20,\n",
    "                              min_data_in_leaf =20, \n",
    "                              min_sum_hessian_in_leaf = 11,\n",
    "                              metric = 'rmse',\n",
    "                              lambda_l1 = 0.3,\n",
    "                              nthread = 4,\n",
    "                              )\n",
    "model_cb = cb.CatBoostRegressor(iterations=1000, depth=6, learning_rate=0.5,eval_metric = \"R2\",leaf_estimation_method = \"Newton\",\n",
    "                            l2_leaf_reg=3\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T08:19:40.444283Z",
     "start_time": "2019-06-03T08:19:40.442283Z"
    }
   },
   "source": [
    " 每个人的特征 Stacking \n",
    "     \n",
    "     数据输入第一层模型，输出即将喂给第二层模型特征\n",
    "     \n",
    " 6个Stacking的结果取平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T03:53:32.949977Z",
     "start_time": "2019-06-28T03:53:32.893963Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e7ddfdf153f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一层模型(5折交叉验证取平均)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:47:28.287318Z",
     "start_time": "2019-06-04T15:47:28.278316Z"
    }
   },
   "outputs": [],
   "source": [
    "### 5折stacking\n",
    "def stack(X_train,X_test,y_train):\n",
    "    clfs1 = [ GBoost,model_xgb,model_lgb]\n",
    "    X_train_stack  = np.zeros((X_train.shape[0], len(clfs1)))\n",
    "    X_test_stack = np.zeros((X_test.shape[0], len(clfs1))) \n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "    # skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1)\n",
    "    for i,clf in enumerate(clfs1):\n",
    "        print(\"分类器：{}\".format(clf))\n",
    "        X_stack_test_n = np.zeros((X_test.shape[0], 5))\n",
    "        for j,(trn_idx, val_idx)in enumerate(folds.split(X_train,y_train)):\n",
    "            tr_x = X_train.iloc[trn_idx]\n",
    "            tr_y = y_train.iloc[trn_idx]\n",
    "            clf.fit(tr_x, tr_y)\n",
    "            #生成stacking训练数据集\n",
    "            X_train_stack[val_idx, i] = clf.predict(X_train.iloc[val_idx])\n",
    "            X_stack_test_n[:,j] = clf.predict(X_test)\n",
    "\n",
    "        #生成stacking测试数据集\n",
    "        X_test_stack[:,i] = X_stack_test_n.mean(axis=1) \n",
    "\n",
    "    X_train_stack1 = pd.DataFrame(X_train_stack)\n",
    "    X_test_stack1 = pd.DataFrame(X_test_stack)\n",
    "    X_train_stack1.shape,X_test_stack1.shape\n",
    "    \n",
    "    X_train_stack1 = X_train_stack1.reset_index(drop=True)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test_stack1 = X_test_stack1.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "   ##  第一层模型的输出特征合并\n",
    "    train = pd.concat([X_train_stack1,X_train],axis = 1)\n",
    "    test = pd.concat([X_test_stack1,X_test],axis = 1)\n",
    "    print(train.shape,test.shape)\n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T09:16:37.566267Z",
     "start_time": "2019-06-03T09:16:37.564266Z"
    }
   },
   "source": [
    "## 第二层模型(LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T15:47:37.561467Z",
     "start_time": "2019-06-04T15:47:37.549463Z"
    }
   },
   "outputs": [],
   "source": [
    "def layer2(train,test,target):\n",
    "    params = {\n",
    "        'num_leaves': 31,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'min_child_samples':20,\n",
    "        'objective': 'regression',\n",
    "        'learning_rate': 0.01,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"bagging_fraction\": 0.85,\n",
    "        \"bagging_seed\": 23,\n",
    "        \"metric\": 'rmse',\n",
    "        \"lambda_l1\": 0.3,\n",
    "        \"nthread\": 4,\n",
    "    }\n",
    "    # train,test,target = train[best_fea],test[best_fea],pd.DataFrame(target)\n",
    "    # train,test = X_train_stack,X_test_stack\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "\n",
    "    oof_lgb = np.zeros(len(train))\n",
    "    predictions_lgb = np.zeros(len(test))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "    #     trn_data = lgb.Dataset(train.iloc[trn_idx], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "    #     val_data = lgb.Dataset(train.iloc[val_idx], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx], label=target.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx], label=target.iloc[val_idx])\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(params, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                        early_stopping_rounds=200)\n",
    "\n",
    "        oof_lgb[val_idx] = clf.predict(train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "#         OOF_lgb  = pd.DataFrame()\n",
    "#     #     OOF_lgb[fold_] = clf.predict(train, num_iteration=clf.best_iteration)\n",
    "\n",
    "\n",
    "\n",
    "#         fold_importance_df = pd.DataFrame()\n",
    "#         fold_importance_df[\"feature\"] = train.columns\n",
    "#         fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "#         fold_importance_df[\"fold\"] = fold_ + 1\n",
    "#         feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions_lgb += clf.predict(test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    print(\"CV Score: {:<8.5f}\".format(r2_score(target, oof_lgb)))\n",
    "    import datetime\n",
    "    def create_submission(prediction, score,model_name):\n",
    "        now = datetime.datetime.now()\n",
    "        sub_file = 'D:/城市-房产租金预测/result/submission_' +model_name+ str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "        print ('Creating submission: ', sub_file)\n",
    "    #     print(predictions_lgb.min(),predictions_lgb.max())\n",
    "        pd.DataFrame({ 'trademoney': prediction}).to_csv(sub_file, index=False,header=None)\n",
    "\n",
    "    model_name='lgbm'\n",
    "    score=r2_score(target, oof_lgb)\n",
    "    create_submission(predictions_lgb, score,model_name)\n",
    "\n",
    "#     print(online_score(predictions_lgb))\n",
    "    return predictions_lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T16:09:25.589350Z",
     "start_time": "2019-06-04T15:48:11.687748Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器：GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=4,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=10,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
      "                          n_iter_no_change=None, presort='auto', random_state=5,\n",
      "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "                          verbose=0, warm_start=False)\n",
      "分类器：XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bytree=0.4603, gamma=0.0468, importance_type='gain',\n",
      "             learning_rate=0.05, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=1.7817, missing=None, n_estimators=5000, n_jobs=1,\n",
      "             nthread=-1, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0.464, reg_lambda=0.8571, scale_pos_weight=1, seed=None,\n",
      "             silent=1, subsample=0.5213)\n",
      "分类器：LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, bagging_seed=23,\n",
      "              boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "              colsample_bytree=1.0, feature_fraction=0.85,\n",
      "              feature_fraction_seed=9, importance_type='split', lambda_l1=0.3,\n",
      "              learning_rate=0.01, max_bin=55, max_depth=-1, metric='rmse',\n",
      "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=20,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=720,\n",
      "              n_jobs=-1, nthread=4, num_leaves=31, objective='regression',\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, ...)\n",
      "(40006, 246) (2401, 246)\n",
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 637.271\tvalid_1's rmse: 728.999\n",
      "Early stopping, best iteration is:\n",
      "[391]\ttraining's rmse: 654.186\tvalid_1's rmse: 726.526\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 631.591\tvalid_1's rmse: 771.449\n",
      "Early stopping, best iteration is:\n",
      "[446]\ttraining's rmse: 638.904\tvalid_1's rmse: 770.883\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 636.878\tvalid_1's rmse: 744.928\n",
      "Early stopping, best iteration is:\n",
      "[453]\ttraining's rmse: 643.491\tvalid_1's rmse: 744.637\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 639.65\tvalid_1's rmse: 727.961\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's rmse: 653.954\tvalid_1's rmse: 726.924\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 639.949\tvalid_1's rmse: 707.226\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttraining's rmse: 654.493\tvalid_1's rmse: 705.953\n",
      "CV Score: 0.91295 \n",
      "Creating submission:  D:/城市-房产租金预测/result/submission_lgbm0.9129457558619913_2019-06-05-00-09.csv\n"
     ]
    }
   ],
   "source": [
    "pinkman_train,pinkman_test = stack(pinkman_train,pinkman_test,pinkman_target)\n",
    "pinkman_pre = layer2(pinkman_train,pinkman_test,pinkman_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T16:31:54.699604Z",
     "start_time": "2019-06-04T16:09:25.591283Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器：GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=4,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=10,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
      "                          n_iter_no_change=None, presort='auto', random_state=5,\n",
      "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "                          verbose=0, warm_start=False)\n",
      "分类器：XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bytree=0.4603, gamma=0.0468, importance_type='gain',\n",
      "             learning_rate=0.05, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=1.7817, missing=None, n_estimators=5000, n_jobs=1,\n",
      "             nthread=-1, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0.464, reg_lambda=0.8571, scale_pos_weight=1, seed=None,\n",
      "             silent=1, subsample=0.5213)\n",
      "分类器：LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, bagging_seed=23,\n",
      "              boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "              colsample_bytree=1.0, feature_fraction=0.85,\n",
      "              feature_fraction_seed=9, importance_type='split', lambda_l1=0.3,\n",
      "              learning_rate=0.01, max_bin=55, max_depth=-1, metric='rmse',\n",
      "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=20,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=720,\n",
      "              n_jobs=-1, nthread=4, num_leaves=31, objective='regression',\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, ...)\n",
      "(39618, 46) (2401, 46)\n",
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 596.464\tvalid_1's rmse: 674.191\n",
      "Early stopping, best iteration is:\n",
      "[423]\ttraining's rmse: 604.026\tvalid_1's rmse: 673.423\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 600.988\tvalid_1's rmse: 653.074\n",
      "Early stopping, best iteration is:\n",
      "[422]\ttraining's rmse: 608.818\tvalid_1's rmse: 652.428\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 594.987\tvalid_1's rmse: 680.338\n",
      "Early stopping, best iteration is:\n",
      "[493]\ttraining's rmse: 595.559\tvalid_1's rmse: 680.308\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 599.249\tvalid_1's rmse: 665.247\n",
      "Early stopping, best iteration is:\n",
      "[464]\ttraining's rmse: 602.613\tvalid_1's rmse: 665.175\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 604.62\tvalid_1's rmse: 633.465\n",
      "Early stopping, best iteration is:\n",
      "[450]\ttraining's rmse: 609.507\tvalid_1's rmse: 633.153\n",
      "CV Score: 0.92215 \n",
      "Creating submission:  D:/城市-房产租金预测/result/submission_lgbm0.922154808362788_2019-06-05-00-20.csv\n",
      "分类器：GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=4,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=10,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
      "                          n_iter_no_change=None, presort='auto', random_state=5,\n",
      "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "                          verbose=0, warm_start=False)\n",
      "分类器：XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bytree=0.4603, gamma=0.0468, importance_type='gain',\n",
      "             learning_rate=0.05, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=1.7817, missing=None, n_estimators=5000, n_jobs=1,\n",
      "             nthread=-1, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0.464, reg_lambda=0.8571, scale_pos_weight=1, seed=None,\n",
      "             silent=1, subsample=0.5213)\n",
      "分类器：LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, bagging_seed=23,\n",
      "              boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "              colsample_bytree=1.0, feature_fraction=0.85,\n",
      "              feature_fraction_seed=9, importance_type='split', lambda_l1=0.3,\n",
      "              learning_rate=0.01, max_bin=55, max_depth=-1, metric='rmse',\n",
      "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=20,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=720,\n",
      "              n_jobs=-1, nthread=4, num_leaves=31, objective='regression',\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, ...)\n",
      "(39618, 45) (2401, 45)\n",
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 593.622\tvalid_1's rmse: 674.783\n",
      "Early stopping, best iteration is:\n",
      "[386]\ttraining's rmse: 605.589\tvalid_1's rmse: 673.914\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 597.895\tvalid_1's rmse: 649.312\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's rmse: 603.467\tvalid_1's rmse: 649.016\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 593.009\tvalid_1's rmse: 677.686\n",
      "Early stopping, best iteration is:\n",
      "[573]\ttraining's rmse: 587.159\tvalid_1's rmse: 677.573\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 596.665\tvalid_1's rmse: 657.395\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's rmse: 583.773\tvalid_1's rmse: 656.869\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 601.638\tvalid_1's rmse: 634.935\n",
      "Early stopping, best iteration is:\n",
      "[460]\ttraining's rmse: 605.497\tvalid_1's rmse: 634.786\n",
      "CV Score: 0.92274 \n",
      "Creating submission:  D:/城市-房产租金预测/result/submission_lgbm0.9227391318164019_2019-06-05-00-31.csv\n"
     ]
    }
   ],
   "source": [
    "Jason_train_v1.rename(columns={'train_pre':'pre'}, inplace = True)\n",
    "Jason_test_v1.rename(columns={'test_pre':'pre'}, inplace = True)\n",
    "\n",
    "Jason_train_v2.rename(columns={'train_pre':'pre'}, inplace = True)\n",
    "Jason_test_v2.rename(columns={'test_pre':'pre'}, inplace = True)\n",
    "\n",
    "Jason_train_v1,Jason_test_v1 = stack(Jason_train_v1,Jason_test_v1,Jason_target_v1)\n",
    "Jason_pre_v1 = layer2(Jason_train_v1,Jason_test_v1,Jason_target_v1)\n",
    "\n",
    "Jason_train_v2,Jason_test_v2 = stack(Jason_train_v2,Jason_test_v2,Jason_target_v2)\n",
    "Jason_pre_v2 = layer2(Jason_train_v2,Jason_test_v2,Jason_target_v2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T16:58:27.367866Z",
     "start_time": "2019-06-04T16:31:54.702606Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器：GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=4,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=10,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
      "                          n_iter_no_change=None, presort='auto', random_state=5,\n",
      "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "                          verbose=0, warm_start=False)\n",
      "分类器：XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bytree=0.4603, gamma=0.0468, importance_type='gain',\n",
      "             learning_rate=0.05, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=1.7817, missing=None, n_estimators=5000, n_jobs=1,\n",
      "             nthread=-1, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0.464, reg_lambda=0.8571, scale_pos_weight=1, seed=None,\n",
      "             silent=1, subsample=0.5213)\n",
      "分类器：LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, bagging_seed=23,\n",
      "              boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "              colsample_bytree=1.0, feature_fraction=0.85,\n",
      "              feature_fraction_seed=9, importance_type='split', lambda_l1=0.3,\n",
      "              learning_rate=0.01, max_bin=55, max_depth=-1, metric='rmse',\n",
      "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=20,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=720,\n",
      "              n_jobs=-1, nthread=4, num_leaves=31, objective='regression',\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, ...)\n",
      "(40126, 235) (2401, 235)\n",
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 492.953\tvalid_1's rmse: 440.892\n",
      "Early stopping, best iteration is:\n",
      "[608]\ttraining's rmse: 484.211\tvalid_1's rmse: 440.36\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 491.129\tvalid_1's rmse: 456.802\n",
      "Early stopping, best iteration is:\n",
      "[701]\ttraining's rmse: 476.289\tvalid_1's rmse: 455.954\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 491.796\tvalid_1's rmse: 455.528\n",
      "Early stopping, best iteration is:\n",
      "[774]\ttraining's rmse: 472.685\tvalid_1's rmse: 454.105\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 492.582\tvalid_1's rmse: 441.029\n",
      "Early stopping, best iteration is:\n",
      "[541]\ttraining's rmse: 489.04\tvalid_1's rmse: 440.766\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 409.907\tvalid_1's rmse: 763.909\n",
      "Early stopping, best iteration is:\n",
      "[380]\ttraining's rmse: 421.429\tvalid_1's rmse: 762.901\n",
      "CV Score: 0.95626 \n",
      "Creating submission:  D:/城市-房产租金预测/result/submission_lgbm0.9562620778412464_2019-06-05-00-58.csv\n"
     ]
    }
   ],
   "source": [
    "heitao_train,heitao_test = stack(heitao_train,heitao_test,heitao_target)\n",
    "heitao_pre = layer2(heitao_train,heitao_test,heitao_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T17:42:57.655209Z",
     "start_time": "2019-06-04T16:58:27.369867Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器：GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=4,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=10,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
      "                          n_iter_no_change=None, presort='auto', random_state=5,\n",
      "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "                          verbose=0, warm_start=False)\n",
      "分类器：XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bytree=0.4603, gamma=0.0468, importance_type='gain',\n",
      "             learning_rate=0.05, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=1.7817, missing=None, n_estimators=5000, n_jobs=1,\n",
      "             nthread=-1, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0.464, reg_lambda=0.8571, scale_pos_weight=1, seed=None,\n",
      "             silent=1, subsample=0.5213)\n",
      "分类器：LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, bagging_seed=23,\n",
      "              boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "              colsample_bytree=1.0, feature_fraction=0.85,\n",
      "              feature_fraction_seed=9, importance_type='split', lambda_l1=0.3,\n",
      "              learning_rate=0.01, max_bin=55, max_depth=-1, metric='rmse',\n",
      "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=20,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=720,\n",
      "              n_jobs=-1, nthread=4, num_leaves=31, objective='regression',\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, ...)\n",
      "(37663, 524) (4870, 524)\n",
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 656.27\tvalid_1's rmse: 764.993\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's rmse: 674.602\tvalid_1's rmse: 762.53\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 656.938\tvalid_1's rmse: 776.618\n",
      "Early stopping, best iteration is:\n",
      "[376]\ttraining's rmse: 681.253\tvalid_1's rmse: 772.241\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 649.321\tvalid_1's rmse: 807.727\n",
      "Early stopping, best iteration is:\n",
      "[387]\ttraining's rmse: 670.344\tvalid_1's rmse: 803.354\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 651.326\tvalid_1's rmse: 803.962\n",
      "Early stopping, best iteration is:\n",
      "[351]\ttraining's rmse: 682.58\tvalid_1's rmse: 796.42\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 649.048\tvalid_1's rmse: 805.452\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttraining's rmse: 666.368\tvalid_1's rmse: 802.776\n",
      "CV Score: 0.92821 \n",
      "Creating submission:  D:/城市-房产租金预测/result/submission_lgbm0.9282102104168221_2019-06-05-01-42.csv\n"
     ]
    }
   ],
   "source": [
    "airen_train,airen_test = stack(airen_train,airen_test,airen_target)\n",
    "airen_pre = layer2(airen_train,airen_test,airen_target)\n",
    "# 由于爱人的使用了test_a的数据 所以需要切分一下\n",
    "airen_pre = airen_pre[:len(heitao_pre)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T18:09:43.068346Z",
     "start_time": "2019-06-04T17:42:57.669212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类器：GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=4,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=10,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=3000,\n",
      "                          n_iter_no_change=None, presort='auto', random_state=5,\n",
      "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "                          verbose=0, warm_start=False)\n",
      "分类器：XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bytree=0.4603, gamma=0.0468, importance_type='gain',\n",
      "             learning_rate=0.05, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=1.7817, missing=None, n_estimators=5000, n_jobs=1,\n",
      "             nthread=-1, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0.464, reg_lambda=0.8571, scale_pos_weight=1, seed=None,\n",
      "             silent=1, subsample=0.5213)\n",
      "分类器：LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, bagging_seed=23,\n",
      "              boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "              colsample_bytree=1.0, feature_fraction=0.85,\n",
      "              feature_fraction_seed=9, importance_type='split', lambda_l1=0.3,\n",
      "              learning_rate=0.01, max_bin=55, max_depth=-1, metric='rmse',\n",
      "              min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=20,\n",
      "              min_split_gain=0.0, min_sum_hessian_in_leaf=11, n_estimators=720,\n",
      "              n_jobs=-1, nthread=4, num_leaves=31, objective='regression',\n",
      "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, ...)\n",
      "(40006, 245) (2401, 245)\n",
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 634.643\tvalid_1's rmse: 725.25\n",
      "Early stopping, best iteration is:\n",
      "[383]\ttraining's rmse: 652.227\tvalid_1's rmse: 723.203\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 628.524\tvalid_1's rmse: 760.698\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttraining's rmse: 635.955\tvalid_1's rmse: 759.997\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 632.311\tvalid_1's rmse: 738.787\n",
      "Early stopping, best iteration is:\n",
      "[467]\ttraining's rmse: 636.44\tvalid_1's rmse: 738.164\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 637.007\tvalid_1's rmse: 724.855\n",
      "Early stopping, best iteration is:\n",
      "[383]\ttraining's rmse: 654.254\tvalid_1's rmse: 722.587\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 637.664\tvalid_1's rmse: 701.509\n",
      "Early stopping, best iteration is:\n",
      "[366]\ttraining's rmse: 658.823\tvalid_1's rmse: 698.624\n",
      "CV Score: 0.91448 \n",
      "Creating submission:  D:/城市-房产租金预测/result/submission_lgbm0.9144805242714281_2019-06-05-02-09.csv\n"
     ]
    }
   ],
   "source": [
    "yb_train,yb_test = stack(yb_train,yb_test,yb_target)\n",
    "yb_pre = layer2(yb_train,yb_test,yb_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T00:43:24.578509Z",
     "start_time": "2019-06-05T00:43:24.539490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果最大值：15118.27064880905,预测结果最小值：1355.7491137830068\n",
      "对比913分数:0.9930013663744774\n",
      "对比918分数:0.997513390896551\n",
      "对比919分数:0.9985484433504949\n"
     ]
    }
   ],
   "source": [
    "pre = (pinkman_pre + Jason_pre_v1 + Jason_pre_v2 + airen_pre+ yb_pre+ heitao_pre)/6\n",
    "online_score(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T00:43:25.961812Z",
     "start_time": "2019-06-05T00:43:25.947808Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pre).to_csv(\"0.9985484433504949.csv\",header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T00:43:57.613951Z",
     "start_time": "2019-06-05T00:43:57.579944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果最大值：15606.824182987737,预测结果最小值：1222.1235852723944\n",
      "对比913分数:0.980332815979435\n",
      "对比918分数:0.9895456161867269\n",
      "对比919分数:0.9921747694981579\n"
     ]
    }
   ],
   "source": [
    "online_score(heitao_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T13:42:50.861704Z",
     "start_time": "2019-06-03T13:42:42.751811Z"
    }
   },
   "outputs": [],
   "source": [
    "log1p_y_train = np.log1p(target)\n",
    "ENet = ElasticNet(alpha=1e-9, l1_ratio=.59, random_state=5)\n",
    "# 采用平滑后的y_train进行模型训练\n",
    "ENet.fit(train, log1p_y_train)\n",
    "# 对训练集预测\n",
    "pred_log1p = ENet.predict(train)\n",
    "# 模型评分\n",
    "score = r2_score(log1p_y_train,pred_log1p)\n",
    "print(score)\n",
    "# 对测试集预测\n",
    "ENet_pred = ENet.predict(test)\n",
    "# 将测试集结果去掉平滑\n",
    "ENet_pred = np.expm1(ENet_pred)\n",
    "# 保存文件\n",
    "pd.DataFrame(ENet_pred).to_csv(\"ENet_{}.csv\".format(score),header=None,index=None)\n",
    "online_score(ENet_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T13:37:39.179848Z",
     "start_time": "2019-06-03T13:37:30.480155Z"
    }
   },
   "outputs": [],
   "source": [
    "log1p_y_train = np.log1p(target)\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=1e-9, l1_ratio=.59, random_state=5))\n",
    "# 采用平滑后的y_train进行模型训练\n",
    "ENet.fit(train, log1p_y_train)\n",
    "# 对训练集预测\n",
    "pred_log1p = ENet.predict(train)\n",
    "# 模型评分\n",
    "score = r2_score(log1p_y_train,pred_log1p)\n",
    "print(score)\n",
    "# 对测试集预测\n",
    "ENet_pred = ENet.predict(test)\n",
    "# 将测试集结果去掉平滑\n",
    "ENet_pred = np.expm1(ENet_pred)\n",
    "# 保存文件\n",
    "pd.DataFrame(ENet_pred).to_csv(\"ENet_{}.csv\".format(score),header=None,index=None)\n",
    "online_score(ENet_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T13:38:01.473439Z",
     "start_time": "2019-06-03T13:37:53.128558Z"
    }
   },
   "outputs": [],
   "source": [
    "log1p_y_train = np.log1p(target)\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =1e-9, random_state=5))\n",
    "\n",
    "# 采用平滑后的y_train进行模型训练\n",
    "lasso.fit(train, log1p_y_train)\n",
    "# 对训练集预测\n",
    "pred_log1p = lasso.predict(train)\n",
    "# 模型评分\n",
    "score = r2_score(log1p_y_train,pred_log1p)\n",
    "print(score)\n",
    "# 对测试集预测\n",
    "pred = lasso.predict(test)\n",
    "# 将测试集结果去掉平滑\n",
    "lasso_pred = np.expm1(pred)\n",
    "# 保存结果\n",
    "pd.DataFrame(lasso_pred).to_csv(\"lasso_{}.csv\".format(score),header=None,index=None)\n",
    "print(online_score(lasso_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T13:40:43.642318Z",
     "start_time": "2019-06-03T13:40:43.638319Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = (predictions_lgb * 0.9 +  GBoost_pred * 0.5 + xgb_pred * 0.5)/(0.9+0.5+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T13:40:44.292465Z",
     "start_time": "2019-06-03T13:40:44.262458Z"
    }
   },
   "outputs": [],
   "source": [
    "print(online_score(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID处理(抛弃)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:10:52.933491Z",
     "start_time": "2019-06-03T14:10:52.745451Z"
    }
   },
   "outputs": [],
   "source": [
    "heitao_ID = np.array(heitao_train[\"ID\"])\n",
    "pinkman_ID = np.array(pinkman_train[\"ID\"])\n",
    "Jason_ID_v1 = np.array(Jason_train_v1[\"ID\"])\n",
    "Jason_ID_v2 = np.array(Jason_train_v2[\"ID\"])\n",
    "hero_ID = np.array(hero_train[\"ID\"])\n",
    "print(len(heitao_ID),len(pinkman_ID))\n",
    "ID = set(heitao_ID) & set(pinkman_ID) & set(Jason_ID_v1) & set(Jason_ID_v2)  & set(hero_ID)\n",
    "print(len(ID))\n",
    "# ID = pd.DataFrame(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:11:12.703387Z",
     "start_time": "2019-06-03T14:11:12.697386Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_for_ID(train,test):\n",
    "    drop_ID = set(train.ID).difference(ID)\n",
    "    print(\"原始数据集大小{},将要删除{}个ID,正在删除...\".format(train.shape,len(drop_ID)))\n",
    "    for i in drop_ID:\n",
    "        train.drop(train[(train['ID'] == i)].index, inplace=True)\n",
    "#         test.drop(test[(test['ID'] == i)].index, inplace=True)\n",
    "    print(\"已删除ID,正在根据ID排序...\")\n",
    "    train.sort_values(by=\"ID\")\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    print(\"根据ID排序完成！！！\")\n",
    "    print(\"剩余训练集大小{}...\".format(train.shape))\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:12:13.362648Z",
     "start_time": "2019-06-03T14:11:18.153617Z"
    }
   },
   "outputs": [],
   "source": [
    "pinkman_train,pinkman_test = drop_for_ID(pinkman_train,pinkman_test)\n",
    "# pinkman_train[\"ID\"]\n",
    "\n",
    "heitao_train,heitao_test = drop_for_ID(heitao_train,heitao_test)\n",
    "# heitao_train[\"ID\"]\n",
    "\n",
    "Jason_train_v1,Jason_test_v1 = drop_for_ID(Jason_train_v1,Jason_test_v1)\n",
    "# Jason_train_v1[\"ID\"]\n",
    "\n",
    "Jason_train_v2,Jason_test_v2 = drop_for_ID(Jason_train_v2,Jason_test_v2)\n",
    "# Jason_train_v2[\"ID\"]\n",
    "\n",
    "hero_train,hero_test = drop_for_ID(hero_train,hero_test)\n",
    "# hero_train[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:06:14.116764Z",
     "start_time": "2019-06-03T14:06:14.088761Z"
    }
   },
   "outputs": [],
   "source": [
    "# ID处理\n",
    "\n",
    "heitao_ID = np.array(heitao_train[\"ID\"])\n",
    "pinkman_ID = np.array(pinkman_train[\"ID\"])\n",
    "Jason_ID_v1 = np.array(Jason_train_v1[\"ID\"])\n",
    "Jason_ID_v2 = np.array(Jason_train_v2[\"ID\"])\n",
    "hero_ID = np.array(hero_train[\"ID\"])\n",
    "print(len(heitao_ID),len(pinkman_ID))\n",
    "ID = set(heitao_ID) & set(pinkman_ID) & set(Jason_ID_v1) & set(Jason_ID_v2)  & set(hero_ID)\n",
    "print(len(ID))\n",
    "# ID = pd.DataFrame(ID)\n",
    "\n",
    "def drop_for_ID(train,test):\n",
    "    drop_ID = set(train.ID).difference(ID)\n",
    "    print(\"原始数据集大小{},将要删除{}个ID,正在删除...\".format(train.shape,len(drop_ID)))\n",
    "    for i in drop_ID:\n",
    "        train.drop(train[(train['ID'] == i)].index, inplace=True)\n",
    "#         test.drop(test[(test['ID'] == i)].index, inplace=True)\n",
    "    print(\"已删除ID,正在根据ID排序...\")\n",
    "    train.sort_values(by=\"ID\")\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    print(\"根据ID排序完成！！！\")\n",
    "    print(\"剩余训练集大小{}...\".format(train.shape))\n",
    "    return train,test\n",
    "\n",
    "pinkman_train,pinkman_test = drop_for_ID(pinkman_train,pinkman_test)\n",
    "# pinkman_train[\"ID\"]\n",
    "\n",
    "heitao_train,heitao_test = drop_for_ID(heitao_train,heitao_test)\n",
    "# heitao_train[\"ID\"]\n",
    "\n",
    "Jason_train_v1,Jason_test_v1 = drop_for_ID(Jason_train_v1,Jason_test_v1)\n",
    "# Jason_train_v1[\"ID\"]\n",
    "\n",
    "Jason_train_v2,Jason_test_v2 = drop_for_ID(Jason_train_v2,Jason_test_v2)\n",
    "# Jason_train_v2[\"ID\"]\n",
    "\n",
    "hero_train,hero_test = drop_for_ID(hero_train,hero_test)\n",
    "# hero_train[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T04:51:56.673887Z",
     "start_time": "2019-06-06T04:51:56.583868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果最大值：0    15147.922324\n",
      "dtype: float64,预测结果最小值：0    1332.325739\n",
      "dtype: float64\n",
      "对比913分数:0.9932508501940013\n",
      "对比918分数:0.9980113048560919\n",
      "对比919分数:0.9998189065713886\n"
     ]
    }
   ],
   "source": [
    "pre= pd.read_csv(\"D:/AIfuture/CODE1(如果可以，麻烦使用这一版，之前那版在整理时出现了bug，但是结果都一样)/data/submit.csv\",engine = \"python\",header = None)\n",
    "\n",
    "online_score(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "327.68px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
